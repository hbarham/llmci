This is a code for LLM and vision model, to open browser, then vision model describe what is on screen, yolo model detects the coordinate of buttons and field, both information are sent to the llm model, the llm model writes python script based on recieved data and coordinate to use mouse and keyboard to interact with screen to perform browsing the web and filling fields etc.. 
you can run the code: python main.py and install required dependencies.
